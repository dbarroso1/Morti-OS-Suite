{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\morti_os_suite\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Importing the Libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Cornell Movie Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open('data/movie_lines.txt', \n",
    "             encoding='utf-8',\n",
    "             errors='ignore').read().split('\\n')\n",
    "conversations = open('data/movie_conversations.txt', \n",
    "             encoding='utf-8',\n",
    "             errors='ignore').read().split('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2line = {}\n",
    "conv_ids = []\n",
    "\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "clean_q = []\n",
    "clean_a = []\n",
    "\n",
    "w2c = {}\n",
    "\n",
    "# hyper parameters\n",
    "threshold = 24\n",
    "qw2int = {}\n",
    "aw2int = {}\n",
    "word_num = 0\n",
    "\n",
    "tokens = ['<PAD>','<EOS>','<OUT>','<SOS>']\n",
    "\n",
    "q2int = []\n",
    "a2int = []\n",
    "\n",
    "s_clean_q = []\n",
    "s_clean_a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Dictionary that maps the line to its ID\n",
    "for line in lines:\n",
    "    _line = line.split(' +++$+++ ')\n",
    "    if len(_line) == 5:\n",
    "        id2line[_line[0]] = _line[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of all the conversations\n",
    "for conversation in conversations[:-1]:\n",
    "    _conv = conversation.split(' +++$+++ ')[-1][1:-1].replace(\"'\",\"\").replace(\" \",\"\")\n",
    "    conv_ids.append(_conv.split(','))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the questions and Answers to individual lists\n",
    "for conv in conv_ids:\n",
    "    for i in range(len(conv) - 1):\n",
    "        questions.append(id2line[conv[i]])\n",
    "        answers.append(id2line[conv[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaing the Dictionaries\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"y'know\", \"you know\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"\\!\", \"\", text)\n",
    "    text = re.sub(r\"\\...\", \"\", text)\n",
    "    text = re.sub(r\"!@#$%^&*()_+-=`~;',./:<>?\", \"\", text)\n",
    "    text = re.sub(r\"0123456789\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in questions:\n",
    "    clean_q.append(clean_text(question))\n",
    "for answer in answers:\n",
    "    clean_a.append(clean_text(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary that maps each word to its number of ocurrences'\n",
    "for q in clean_q:\n",
    "    for word in q.split():\n",
    "        if word not in w2c:\n",
    "            w2c[word] = 1\n",
    "        else:\n",
    "            w2c[word] += 1\n",
    "            \n",
    "for a in clean_a:\n",
    "    for word in a.split():\n",
    "        if word not in w2c:\n",
    "            w2c[word] = 1\n",
    "        else:\n",
    "            w2c[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, count in w2c.items():\n",
    "        if count >= threshold:\n",
    "            qw2int[word] = word_num\n",
    "            word_num += 1\n",
    "for word, count in w2c.items():\n",
    "        if count >= threshold:\n",
    "            aw2int[word] = word_num\n",
    "            word_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the last tokens to theres 2 dictionaries\n",
    "for token in tokens:\n",
    "    qw2int[token] = len(qw2int) + 1\n",
    "for token in tokens:\n",
    "    aw2int[token] = len(aw2int) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ai2word = {w_i: w for w, w_i in aw2int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(clean_a)):\n",
    "    clean_a[i] += '<EOS>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in clean_q:\n",
    "    ints = []\n",
    "    for word in question.split():\n",
    "        if word not in qw2int:\n",
    "            ints.append(qw2int['<OUT>'])\n",
    "        else:\n",
    "            ints.append(qw2int[word])\n",
    "    q2int.append(ints)\n",
    "    \n",
    "for a in clean_a:\n",
    "    ints = []\n",
    "    for word in answer.split():\n",
    "        if word not in aw2int:\n",
    "            ints.append(aw2int['<OUT>'])\n",
    "        else:\n",
    "            ints.append(aw2int[word])\n",
    "    a2int.append(ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting Questions and Answers by the length of the question\n",
    "for length in range(1,25 + 1):\n",
    "    for i in enumerate(q2int):\n",
    "        if len(i[1]) == length:\n",
    "            s_clean_q.append(q2int[[i[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = {\"blue\":\"color\",\"Water\":\"Wet\",\"List\":[1,2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
